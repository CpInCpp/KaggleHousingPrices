{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, Lasso, RidgeCV, ElasticNetCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from modelling_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing for Models and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read Data files\n",
    "dict_dictonary = {}\n",
    "housing, housing_features, feat_labels = read_and_clean(filepath = \"../data/clean_train.csv\")\n",
    "htest_id, htest_features, htest_labels = read_and_clean(filepath = \"../data/clean_test.csv\", test = True)\n",
    "training = housing_features\n",
    "testing = htest_features\n",
    "\n",
    "#### Process and Generate Train Test Splits\n",
    "test_col = testing.columns\n",
    "train_col = training.columns\n",
    "\n",
    "missing = [x for x in train_col if x not in test_col]\n",
    "needed = [x for x in test_col if x not in train_col]\n",
    "\n",
    "training = training.drop(missing, axis=1)\n",
    "testing = testing.drop(needed, axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(training, housing.saleprice, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Hyperparameters...\n",
      "Best Alpha Found: 9e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train each linear model on the train test splits\n",
    "from sklearn import linear_model as lm\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "## Split Training / Testing Data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(training, housing.saleprice, test_size = 0.2, random_state=42)\n",
    "\n",
    "## Build the Model Set\n",
    "alpha_steps = (1e-5,1e-2,200)\n",
    "steps = np.linspace(1,0.8,11)\n",
    "lasso = lm.Lasso()\n",
    "ridge = lm.Ridge()\n",
    "elasticnets = [lm.ElasticNet(l1_ratio = i) for i in steps[1:]]\n",
    "names = ['Lasso'] + [str(round(i,2)) for i in steps[1:]]\n",
    "modelList = pd.Series([lasso] + elasticnets, index = names)\n",
    "\n",
    "## Hyperparameter Tuning\n",
    "print('Tuning Hyperparameters...')\n",
    "param_grid = {'max_iter': [10,100,1000],\n",
    "            'alpha':np.linspace(1e-7,9e-7,100)}\n",
    "grid = ms.GridSearchCV(modelList.Lasso,param_grid,scoring='r2',cv=10)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_iter = grid.best_params_['max_iter']\n",
    "print('Best Alpha Found: {}\\n'.format(best_alpha))\n",
    "#modelList.apply(lambda x: x.set_params(alpha = best_alpha, max_iter = best_iter))\n",
    "\n",
    "\n",
    "## Feature Selection\n",
    "#print(\"Running Lasso Regression for Feature Selection...\")\n",
    "#modelList.Lasso.fit(X_train, Y_train)\n",
    "#drop_col = list(training.columns[np.where(modelList.Lasso.coef_ == 0)[0]])\n",
    "#print(\"Dropping {} columns\\n\".format(len(drop_col)))\n",
    "#training = training.drop(drop_col, axis = 1)\n",
    "#testing = testing.drop(drop_col, axis = 1)\n",
    "\n",
    "#results = modelStack(training, testing, housing.saleprice, produce_submission = True, n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid.cv_results_['mean_train_score']\n",
    "alphas = grid.cv_results_['param_alpha']\n",
    "iters = grid.cv_results_['param_max_iter']\n",
    "df = pd.DataFrame({'Score':scores,'Alpha':alphas,'Iters':iters})\n",
    "X, Y = np.meshgrid(alphas, iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission(htest_id, results, \"submission_stacked.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
