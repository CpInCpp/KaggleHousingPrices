{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from modelling_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olympus\\Project\\machina_ex_kaggle\\modelling\\modelling_functions.py:107: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  housing.col, id_dictonary = to_numeric(housing, col, 'SalePrice')\n"
     ]
    }
   ],
   "source": [
    "#### Read Data files\n",
    "housing, housing_features, feat_labels, dict_dictonary = read_and_clean(filepath = \"../data/clean_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olympus\\Project\\machina_ex_kaggle\\modelling\\modelling_functions.py:91: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  housing.col, id_dictonary = to_numeric_test(housing, col, dictonary)\n"
     ]
    }
   ],
   "source": [
    "htest_id, htest_features, htest_labels, htest_dictonary = read_and_clean(filepath = \"../data/clean_test.csv\", test = True, dictonary = dict_dictonary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "htrain, htest, ptrain, ptest = train_test_split(housing_features, housing.saleprice, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 1288, 2377, 3466, 4555, 5644, 6733, 7822, 8911, 10000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 29, 48, 67, 86, 105, 124, 143, 162, 181, 200, None], 'min_samples_split': [2, 5, 10, 15, 20, 30, 40], 'min_samples_leaf': [1, 2, 4, 8, 16, 32, 64], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 10000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 200, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 20, 30, 40]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8, 16, 32, 64]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 636 tasks      | elapsed: 22.4min\n",
      "C:\\Users\\Olympus\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 1001 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1446 tasks      | elapsed: 55.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1973 tasks      | elapsed: 76.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2580 tasks      | elapsed: 99.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 115.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=1000, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 1288, 2377, 3466, 4555, 5644, 6733, 7822, 8911, 10000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 29, 48, 67, 86, 105, 124, 143, 162, 181, 200, None], 'min_samples_split': [2, 5, 10, 15, 20, 30, 40], 'min_samples_leaf': [1, 2, 4, 8, 16, 32, 64], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 1000, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(htrain, ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 4555,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 162,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mssubclass', 'lotfrontage', 'lotarea', 'overallqual', 'yearbuilt',\n",
      "       'yearremodadd', 'exterqual', 'foundation', 'bsmtqual', 'bsmtfinsf1',\n",
      "       'totalbsmtsf', 'centralair', 'x1stflrsf', 'x2ndflrsf', 'grlivarea',\n",
      "       'fullbath', 'kitchenqual', 'totrmsabvgrd', 'fireplaces', 'fireplacequ',\n",
      "       'garagetype', 'garageyrblt', 'garagefinish', 'garagecars', 'garagearea',\n",
      "       'openporchsf'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=1800, \n",
    "                            random_state=99, \n",
    "                            n_jobs=-1, \n",
    "                            min_samples_split = 2, \n",
    "                            min_samples_leaf = 1, \n",
    "                            max_features = 'sqrt', \n",
    "                            max_depth = 162,\n",
    "                            bootstrap = False)\n",
    "sfm = SelectFromModel(clf, threshold = 0.01)\n",
    "sfm.fit(htrain, ptrain)\n",
    "\n",
    "# ## Not Finished\n",
    "# # Measure Feature Importance\n",
    "feature_selected = []\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "     feature_selected.append(feat_labels[feature_list_index])\n",
    "proxy = feature_selected\n",
    "#trimmed = ['x1stflrsf', 'x2ndflrsf', 'garagecars', 'overallcond', 'saleprice', 'Unnamed: 0', 'bsmtfinsf1']\n",
    "housing_features = housing_features[proxy]\n",
    "#housing_features = housing_features[trimmed_features]\n",
    "print(housing_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trim = ['lotfrontage', 'lotarea', 'landcontour', 'lotconfig', 'condition1', 'roofmatl']\n",
    "features = housing_features.drop(trim, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mssubclass', 'mszoning', 'street', 'alley', 'neighborhood', 'bldgtype',\n",
       "       'housestyle', 'overallqual', 'yearbuilt', 'yearremodadd', 'roofstyle',\n",
       "       'exterior1st', 'exterior2nd', 'masvnrtype', 'masvnrarea', 'exterqual',\n",
       "       'bsmtqual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mssubclass', 'lotarea', 'neighborhood', 'overallqual', 'yearbuilt',\n",
       "       'yearremodadd', 'masvnrarea', 'exterqual', 'foundation', 'bsmtqual',\n",
       "       'bsmtfintype1', 'bsmtunfsf', 'totalbsmtsf', 'heatingqc', 'centralair',\n",
       "       'grlivarea', 'fullbath', 'bedroomabvgr', 'kitchenqual', 'totrmsabvgrd',\n",
       "       'fireplaces', 'fireplacequ', 'garagetype', 'garageyrblt',\n",
       "       'garagefinish', 'garagecars', 'garagearea', 'garagequal', 'garagecond',\n",
       "       'openporchsf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm, _ = run_linear_model(housing, \n",
    "                         features.columns, \n",
    "                         housing.saleprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "htrain, htest, ptrain, ptest = train_test_split(features,\n",
    "                                                housing.saleprice,\n",
    "                                                test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(htrain, ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6987053601688558"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(htest, ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12.109011\n",
       "2    12.317167\n",
       "3    11.849398\n",
       "4    12.429216\n",
       "5    11.870600\n",
       "6    12.634603\n",
       "7    12.206073\n",
       "8    11.774520\n",
       "9    11.678440\n",
       "Name: saleprice, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.saleprice[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "htest_features = htest_features.loc[:, features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8036953062490403"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(htest, ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lm.predict(htest_features) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.84999164, 15.06585999, 15.08500229, 14.83627072, 15.03451169,\n",
       "       14.95373946, 15.01726031, 14.87148124, 14.84570636])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission(htest_id, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
