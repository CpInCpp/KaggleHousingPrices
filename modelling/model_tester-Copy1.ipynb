{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from modelling_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sama/Bootcamp/Project/machina_ex_kaggle/modelling/modelling_functions.py:107: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  housing.col, id_dictonary = to_numeric(housing, col, 'SalePrice')\n"
     ]
    }
   ],
   "source": [
    "#### Read Data files\n",
    "housing, housing_features, feat_labels, dict_dictonary = read_and_clean(filepath = \"../data/clean_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12.247694\n",
       "1       12.109011\n",
       "2       12.317167\n",
       "3       11.849398\n",
       "4       12.429216\n",
       "5       11.870600\n",
       "6       12.634603\n",
       "7       12.206073\n",
       "8       11.774520\n",
       "9       11.678440\n",
       "10      11.771436\n",
       "11      12.751300\n",
       "12      11.877569\n",
       "13      12.540758\n",
       "14      11.964001\n",
       "15      11.790557\n",
       "16      11.911702\n",
       "17      11.407565\n",
       "18      11.976659\n",
       "19      11.842229\n",
       "20      12.692503\n",
       "21      11.845103\n",
       "22      12.345835\n",
       "23      11.774520\n",
       "24      11.944708\n",
       "25      12.454104\n",
       "26      11.811547\n",
       "27      12.631340\n",
       "28      12.242887\n",
       "29      11.134589\n",
       "          ...    \n",
       "1430    12.165980\n",
       "1431    11.875831\n",
       "1432    11.074421\n",
       "1433    12.136187\n",
       "1434    11.982929\n",
       "1435    12.066811\n",
       "1436    11.699405\n",
       "1437    12.885671\n",
       "1438    11.916389\n",
       "1439    12.190959\n",
       "1440    12.160029\n",
       "1441    11.913713\n",
       "1442    12.644328\n",
       "1443    11.703546\n",
       "1444    12.098487\n",
       "1445    11.767568\n",
       "1446    11.969717\n",
       "1447    12.388394\n",
       "1448    11.626254\n",
       "1449    11.429544\n",
       "1450    11.820410\n",
       "1451    12.567551\n",
       "1452    11.884489\n",
       "1453    11.344507\n",
       "1454    12.128111\n",
       "1455    12.072541\n",
       "1456    12.254863\n",
       "1457    12.493130\n",
       "1458    11.864462\n",
       "1459    11.901583\n",
       "Name: saleprice, Length: 1460, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.saleprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sama/Bootcamp/Project/machina_ex_kaggle/modelling/modelling_functions.py:91: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  housing.col, id_dictonary = to_numeric_test(housing, col, dictonary)\n"
     ]
    }
   ],
   "source": [
    "htest_id, htest_features, htest_labels, htest_dictonary = read_and_clean(filepath = \"../data/clean_test.csv\", test = True, dictonary = dict_dictonary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "htrain, htest, ptrain, ptest = train_test_split(housing_features, housing.saleprice, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 1288, 2377, 3466, 4555, 5644, 6733, 7822, 8911, 10000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 29, 48, 67, 86, 105, 124, 143, 162, 181, 200, None], 'min_samples_split': [2, 5, 10, 15, 20, 30, 40], 'min_samples_leaf': [1, 2, 4, 8, 16, 32, 64], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 10000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 200, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 20, 30, 40]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8, 16, 32, 64]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 353 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 636 tasks      | elapsed: 22.4min\n",
      "C:\\Users\\Olympus\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 1001 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1446 tasks      | elapsed: 55.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1973 tasks      | elapsed: 76.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2580 tasks      | elapsed: 99.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed: 115.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=1000, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 1288, 2377, 3466, 4555, 5644, 6733, 7822, 8911, 10000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 29, 48, 67, 86, 105, 124, 143, 162, 181, 200, None], 'min_samples_split': [2, 5, 10, 15, 20, 30, 40], 'min_samples_leaf': [1, 2, 4, 8, 16, 32, 64], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 1000, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(htrain, ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 4555,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 162,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lotfrontage', 'lotarea', 'neighborhood', 'overallqual', 'yearbuilt',\n",
      "       'yearremodadd', 'exterqual', 'foundation', 'bsmtqual', 'bsmtfinsf1',\n",
      "       'totalbsmtsf', 'x1stflrsf', 'x2ndflrsf', 'grlivarea', 'fullbath',\n",
      "       'kitchenqual', 'totrmsabvgrd', 'fireplaces', 'fireplacequ',\n",
      "       'garagetype', 'garagefinish', 'garagecars', 'garagearea'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(n_estimators=4555, \n",
    "                            random_state=99, \n",
    "                            n_jobs=-1, \n",
    "                            min_samples_split = 20, \n",
    "                            min_samples_leaf = 10, \n",
    "                            max_features = 'sqrt', \n",
    "                            max_depth = 162,\n",
    "                            bootstrap = False)\n",
    "sfm = SelectFromModel(clf, threshold = 0.01)\n",
    "sfm.fit(htrain, ptrain)\n",
    "\n",
    "# ## Not Finished\n",
    "# # Measure Feature Importance\n",
    "feature_selected = []\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "     feature_selected.append(feat_labels[feature_list_index])\n",
    "proxy = feature_selected\n",
    "#trimmed = ['x1stflrsf', 'x2ndflrsf', 'garagecars', 'overallcond', 'saleprice', 'Unnamed: 0', 'bsmtfinsf1']\n",
    "housing_features = housing_features[proxy]\n",
    "#housing_features = housing_features[trimmed_features]\n",
    "print(housing_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = ['lotfrontage', 'bsmtfinsf1', 'x2ndflrsf', 'garagefinish']\n",
    "features = housing_features.drop(trim, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lotarea', 'neighborhood', 'overallqual', 'yearbuilt', 'yearremodadd',\n",
       "       'exterqual', 'foundation', 'bsmtqual', 'totalbsmtsf', 'x1stflrsf',\n",
       "       'grlivarea', 'fullbath', 'kitchenqual', 'totrmsabvgrd', 'fireplaces',\n",
       "       'fireplacequ', 'garagetype', 'garagecars', 'garagearea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lotarea', 'neighborhood', 'overallqual', 'yearbuilt', 'yearremodadd',\n",
       "       'exterqual', 'foundation', 'bsmtqual', 'totalbsmtsf', 'x1stflrsf',\n",
       "       'grlivarea', 'fullbath', 'kitchenqual', 'totrmsabvgrd', 'fireplaces',\n",
       "       'fireplacequ', 'garagetype', 'garagecars', 'garagearea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm, _ = run_linear_model(housing, \n",
    "                         features.columns, \n",
    "                         housing.saleprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "htrain, htest, ptrain, ptest = train_test_split(features,\n",
    "                                                housing.saleprice,\n",
    "                                                test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(htrain, ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933485838534185"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(htest, ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lm.predict(htest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017184778471591774"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ptest, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12.109011\n",
       "2    12.317167\n",
       "3    11.849398\n",
       "4    12.429216\n",
       "5    11.870600\n",
       "6    12.634603\n",
       "7    12.206073\n",
       "8    11.774520\n",
       "9    11.678440\n",
       "Name: saleprice, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.saleprice[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "htest_features = htest_features.loc[:, features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lotarea', 'neighborhood', 'overallqual', 'yearbuilt', 'yearremodadd',\n",
       "       'exterqual', 'foundation', 'bsmtqual', 'totalbsmtsf', 'x1stflrsf',\n",
       "       'grlivarea', 'fullbath', 'kitchenqual', 'totrmsabvgrd', 'fireplaces',\n",
       "       'fireplacequ', 'garagetype', 'garagecars', 'garagearea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933485838534185"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(htest, ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.exp(lm.predict(htest_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30131501.62682447, 40761235.1134114 , 43500265.94240554,\n",
       "       38795849.14436171, 42811818.16257785, 34850196.71386831,\n",
       "       41781461.95815577, 45337336.50638179, 24948257.09212951])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission(htest_id, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
